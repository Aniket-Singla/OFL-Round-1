{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ofl v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YIT2mpI_-5dq",
        "bjtVj71rG-wN",
        "6IhV8VQIHitl"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniket-Singla/OFL-Round-1/blob/master/Ofl_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28CppQiXqhlP",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "#imports \n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Lk2MR72HDl",
        "colab_type": "text"
      },
      "source": [
        "# Data Gathering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPo6IbB32BKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "google_drive = GoogleDrive(gauth)\n",
        "\n",
        "#4/sAEiMO7dhEhgoPflGdqnwwEvge0fn_QnXbvmyxUPYku0NQhk8qlQJ6w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYgsyKp56JCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "file_id = '12OYCKGQp1VybvLM157ioLU4Bjt7PWpt-'\n",
        "zip_file = google_drive.CreateFile({'id': file_id})\n",
        "zip_file.GetContentFile('data.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOop9qyN6WQF",
        "colab_type": "code",
        "outputId": "5a02744f-68fe-4cdd-b3c5-bfbf6f3cdc8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace Character + Digits data/Readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: t\n",
            "error:  invalid response [t]\n",
            "replace Character + Digits data/Readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: Character + Digits data/Readme.txt  \n",
            "  inflating: Character + Digits data/characters-digits-test.zip  \n",
            "  inflating: Character + Digits data/characters-digits-train.zip  \n",
            "  inflating: Character + Digits data/characters-digits-mapping.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da1pKsvk6dth",
        "colab_type": "code",
        "outputId": "a6a6ba18-959b-4f39-80bf-e81ffccc72ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "!unzip Character\\ +\\ Digits\\ data/characters-digits-test.zip\n",
        "!unzip Character\\ +\\ Digits\\ data/characters-digits-train.zip\n",
        "!mv Character\\ +\\ Digits\\ data/characters-digits-mapping.txt .\n",
        "!cat Character\\ +\\ Digits\\ data/Readme.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Character + Digits data/characters-digits-test.zip\n",
            "replace characters-digits-test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  Character + Digits data/characters-digits-train.zip\n",
            "replace characters-digits-train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Dataset Details:\n",
            "\n",
            "train: 112,800\n",
            "test: 18,800\n",
            "total: 131,600\n",
            "classes: 47 (Due to the low availabilty of images differentiating characters such as u,v,x,y,etc...)\n",
            "\n",
            "\n",
            "Refer to the characters-digits-mapping file to get the ASCII codes for the labels...\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIT2mpI_-5dq",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI9hhx4E-kSF",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# import required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MiIY95T_JkJ",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# train_df = pd.read_csv('../input/ofl-data/Character + Digits data/characters-digits-train/characters-digits-train.csv', header=None)\n",
        "# test_df = pd.read_csv('../input/ofl-data/Character + Digits data/characters-digits-test/characters-digits-test.csv', header=None)\n",
        "train_df = pd.read_csv('characters-digits-train.csv', header=None)\n",
        "test_df = pd.read_csv('characters-digits-test.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm2W3aIsirxY",
        "colab_type": "code",
        "trusted": true,
        "outputId": "7263d099-1214-48a7-d875-2929a2843d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# mapping = pd.read_csv('../input/ofl-data/Character + Digits data/characters-digits-mapping.txt',header=None,sep=' ')\n",
        "mapping = pd.read_csv('characters-digits-mapping.txt',header=None,sep=' ')\n",
        "mapping.head()\n",
        "classes_t3 = mapping[1].apply(chr).values\n",
        "print(classes_t3)\n",
        "index_to_ascii = mapping[1].values\n",
        "print(index_to_ascii)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'\n",
            " 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
            " 'a' 'b' 'd' 'e' 'f' 'g' 'h' 'n' 'q' 'r' 't']\n",
            "[ 48  49  50  51  52  53  54  55  56  57  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  97  98 100 101 102 103 104 110 113 114 116]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PRS11B-xVVd7",
        "colab_type": "code",
        "outputId": "46d8c075-4a7f-40d6-e4f4-a8ae69f6e07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  778  779  780  781  782  783  784\n",
              "0   41    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "1   39    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "2    9    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "3   26    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "4   44    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjtVj71rG-wN",
        "colab_type": "text"
      },
      "source": [
        "## Creation Of Labels for T1, T2 and T3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03DcubotF9xK",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "labels_train_t3 = train_df[0].values\n",
        "labels_test_t3 = test_df[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "F77IuSnA-nAo",
        "colab": {}
      },
      "source": [
        "labels_train_t1 = (labels_train_t3>9).astype(int)\n",
        "labels_test_t1 = (labels_test_t3>9).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yHg8Pne_Af8",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def create_t2_labels(labels):\n",
        "  labels_t2 = labels.copy()\n",
        "  vowels_index = [10,14,18,24,30,36,39]\n",
        "  for i, label in enumerate(labels):\n",
        "    # print(label)\n",
        "    if label<=9:\n",
        "        if label%2==0:\n",
        "            labels_t2[i]=0\n",
        "        else:\n",
        "            labels_t2[i]=1\n",
        "    else:\n",
        "        if label in vowels_index:\n",
        "            labels_t2[i]=0\n",
        "        else:\n",
        "            labels_t2[i]=1\n",
        "  return labels_t2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2YSzwd0RNvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_t2_labels_eval(labels):\n",
        "  labels_t2 = labels.copy()\n",
        "  vowels_index = [10,14,18,24,30,36,39]\n",
        "  for i, label in enumerate(labels):\n",
        "    # print(label)\n",
        "    if label<=9:\n",
        "        if label%2==0:\n",
        "            labels_t2[i]=0\n",
        "        else:\n",
        "            labels_t2[i]=1\n",
        "    else:\n",
        "        if label in vowels_index:\n",
        "            labels_t2[i]=2\n",
        "        else:\n",
        "            labels_t2[i]=3\n",
        "  return labels_t2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fdmsI1-3fP",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "labels_train_t2 = create_t2_labels(labels_train_t3)\n",
        "labels_train_t2_eval = create_t2_labels_eval(labels_train_t3)\n",
        "labels_test_t2 = create_t2_labels(labels_test_t3)\n",
        "labels_test_t2_eval = create_t2_labels_eval(labels_test_t3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNU3FQ87jrkm",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "train_df['labels_t1'] = labels_train_t1\n",
        "test_df['labels_t1'] = labels_test_t1\n",
        "train_df['labels_t2'] = labels_train_t2\n",
        "train_df['labels_t2_eval'] = labels_train_t2_eval\n",
        "test_df['labels_t2'] = labels_test_t2\n",
        "test_df['labels_t2_eval'] = labels_test_t2_eval\n",
        "train_df['labels_t3'] = labels_train_t3\n",
        "test_df['labels_t3'] = labels_test_t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4e3AiVP_osY",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "images_columns = list(range(1,785))\n",
        "labels_train = train_df[['labels_t1','labels_t2','labels_t3']].values\n",
        "images_train = train_df[images_columns].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7qwnU-lmVVeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_test = test_df[['labels_t1','labels_t2','labels_t3']].values\n",
        "images_test = test_df[images_columns].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OYflINpOhBB",
        "colab_type": "text"
      },
      "source": [
        "# Util + Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IhV8VQIHitl",
        "colab_type": "text"
      },
      "source": [
        "## Creation Of DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH3QSV_oHl5Q",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def create_train_val_dataset(images_train,labels_train,test_size=0.1):\n",
        "\n",
        "    # images_train = images_train.reshape(images_train.shape[0],1,28,28).transpose(0,1,3,2)\n",
        "    # images_test = images_test.reshape(images_test.shape[0],1,28,28).transpose(0,1,3,2)\n",
        "\n",
        "    images_train = images_train.reshape(images_train.shape[0],1,28,28).transpose(0,1,3,2)    \n",
        "    features_train, features_val, targets_train, targets_val = train_test_split(images_train,\n",
        "                                                                                 labels_train,\n",
        "                                                                                 test_size = test_size,\n",
        "                                                                                 random_state = 42) \n",
        "\n",
        "    featuresTrain = torch.from_numpy(features_train).type(torch.FloatTensor)\n",
        "    targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\n",
        "\n",
        "    featuresVal = torch.from_numpy(features_val).type(torch.FloatTensor)\n",
        "    targetsVal = torch.from_numpy(targets_val).type(torch.LongTensor) # data type is long\n",
        "\n",
        "    print(features_train.shape,targets_train.shape)\n",
        "    train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
        "    val = torch.utils.data.TensorDataset(featuresVal,targetsVal)\n",
        "\n",
        "    return train, val\n",
        "    \n",
        "def create_test_dataset(images_test,labels_test):\n",
        "    images_test = images_test.reshape(images_test.shape[0],1,28,28).transpose(0,1,3,2)\n",
        "    featuresTest = torch.from_numpy(images_test).type(torch.FloatTensor)\n",
        "    targetsTest = torch.from_numpy(labels_test).type(torch.LongTensor)\n",
        "    return torch.utils.data.TensorDataset(featuresTest,targetsTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tahyw1jWVVeW",
        "colab_type": "text"
      },
      "source": [
        "## Printing Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWxy-tENZowR",
        "colab_type": "code",
        "trusted": true,
        "outputId": "3966e6b7-a7fc-48a6-8cf5-fcf1303cca35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# fname = 'image.png'\n",
        "pixels = images_train[64553].reshape(28,28)\n",
        "image = Image.fromarray(pixels,'L')\n",
        "# arr = np.asarray(image)\n",
        "plt.imshow(pixels.transpose(), cmap='gray')\n",
        "plt.plot()\n",
        "# image.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEX4gKMIPBEX4gaD+H3i9i1Rka1VJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1SlPyEqezGG",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def imshow(img,title):\n",
        "    npimg = img.numpy() #/ 2 + 0.5  #denormalize image\n",
        "    plt.figure()  # width, height\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Helper function to show a batch\n",
        "def show_images_batch(sample_batched):\n",
        "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
        "    images_batch, label_batch = sample_batched\n",
        "    images_batch = images_batch.type(torch.LongTensor)\n",
        "    # print(images_batch.shape)\n",
        "    batch_size = len(images_batch)\n",
        "    im_size = images_batch.size(2)\n",
        "    grid_border_size = 2\n",
        "\n",
        "    # grid = utils.make_grid(images_batch)\n",
        "    # plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "    img = torchvision.utils.make_grid(images_batch)\n",
        "    label_list_char = []\n",
        "    # print(label_batch.shape)\n",
        "    label_batch_list = list(label_batch.numpy())\n",
        "    for inde in label_batch_list:\n",
        "        label_list_char.append(chr(index_to_ascii[inde]))\n",
        "    imshow(img,title=label_list_char)\n",
        "\n",
        "# for i_batch, sample_batched in enumerate(train_loader_t1):\n",
        "\n",
        "#     # observe 4th batch and stop.\n",
        "#     if i_batch == 3:\n",
        "#         plt.figure()\n",
        "#         show_landmarks_batch(sample_batched)\n",
        "#         plt.axis('off')\n",
        "#         plt.ioff()\n",
        "#         plt.show()\n",
        "#         break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DILVBjogk6GI",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Gathering Models From Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TbwWlf3k-UY",
        "colab_type": "code",
        "outputId": "d2aa1013-58e3-424c-cba6-f041bc3e4c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bACTuDCMtpZ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation + Confusion Matrix Plotter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSqYcjFhMxXo",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader,eval_net,calc_loss=False,loss_fn=None):\n",
        "    eval_net.eval()\n",
        "    total, correct = 0, 0\n",
        "    loss = 0 \n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = eval_net(inputs)\n",
        "\n",
        "        if calc_loss:\n",
        "          loss += loss_fn(outputs, labels)\n",
        "        \n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    eval_net.train()\n",
        "\n",
        "    if calc_loss:\n",
        "      return 100 * correct / total, 100* loss/total\n",
        "      \n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yr87T0MqATos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(data_loader,net,num_labels,classes=None,path=None):\n",
        "    confusion_matrix = np.zeros([num_labels,num_labels])\n",
        "    net= net.cpu()\n",
        "    for data, label in data_loader:\n",
        "        output = net(data)\n",
        "        _, pred = torch.max(output,1)\n",
        "        for x, y in zip(pred.numpy(),label.numpy()):\n",
        "            confusion_matrix[x][y]+= 1\n",
        "            \n",
        "    #plot at last of creating confusion_matrix\n",
        "    if type(classes) == type(None):\n",
        "        classes = np.arange(num_labels)\n",
        "    fig, ax = plt.subplots(figsize=(num_labels*2,num_labels*2))\n",
        "    im = ax.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(confusion_matrix.shape[1]),\n",
        "               yticks=np.arange(confusion_matrix.shape[0]),\n",
        "               xticklabels=classes, yticklabels=classes,\n",
        "               ylabel='True label',\n",
        "               xlabel='Predicted label',\n",
        "               title='Confusion Matrix')\n",
        "    thresh = confusion_matrix.max() / 2.\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "        for j in range(confusion_matrix.shape[1]):\n",
        "            ax.text(j, i, int(confusion_matrix[i, j]),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    if path:\n",
        "        plt.savefig(path)\n",
        "    else :\n",
        "        plt.savefig('confusion.jpg')\n",
        "    net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QWd4UxQNM9X",
        "colab_type": "text"
      },
      "source": [
        "## Device Loader (GPU) and base path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZvkI7s0NRY4",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "load_and_save_mode = True\n",
        "PATH = '/content/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eo92lDsOGV0",
        "colab_type": "text"
      },
      "source": [
        "## Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ff9c6GyOJcA",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def train_model(train_loader,val_loader,test_loader,net,loss_fn,opt,max_epochs=16):\n",
        "  loss_arr = []\n",
        "  loss_epoch_arr = []\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          opt.zero_grad()\n",
        "          \n",
        "          outputs = net(inputs)\n",
        "          loss = loss_fn(outputs, labels)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "          loss_arr.append(loss.item())\n",
        "      loss_epoch_arr.append(loss.item())\n",
        "          \n",
        "      print('Epoch:%d/%d :'%(epoch+1,max_epochs))\n",
        "      print('Validation acc: %0.2f, Test acc : %0.2f' %\n",
        "            ( evaluation(val_loader,net),evaluation(test_loader,net)))\n",
        "      \n",
        "      \n",
        "  plt.plot(loss_epoch_arr)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UESQhctm1b3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_v2(train_loader,net,loss_fn,opt,epoch):\n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device),labels.to(device)\n",
        "      \n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if batch_id % 100 == 0:\n",
        "            pos = epoch * len(train_loader) + batch_id            \n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
        "                epoch, batch_id * len(inputs), len(train_loader.dataset),\n",
        "                100. * batch_id / len(train_loader), loss.data.item()))\n",
        "      \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na9LEPW61eZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_v2(val_loader,net,loss_fn,epoch,train_acc=True,train_loader=None):\n",
        "    \n",
        "    net.eval()\n",
        "    validation_loss,train_loss = 0,0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        if train_acc : \n",
        "          train_accuracy, train_loss = evaluation(train_loader,net,calc_loss=True,loss_fn=loss_fn)\n",
        "          print('\\nTrain set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.\n",
        "                format(train_loss,  train_accuracy))\n",
        "        \n",
        "        validation_accuracy, validation_loss = evaluation(val_loader,net,calc_loss=True,loss_fn=loss_fn)\n",
        "        \n",
        "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.\n",
        "              format(validation_loss,  validation_accuracy))\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "              \n",
        "        # if epoch == args.epochs:\n",
        "        #   plot_confusion_matrix(test_loader,net,num_labels,classes=None,path=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_8T-0SXVVfS",
        "colab_type": "text"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VJNbLKCqVVfh",
        "colab_type": "code",
        "outputId": "6283a8ab-9a2c-48a2-9fd0-62915452b45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train , val = create_train_val_dataset(images_train,labels_train[:,0],test_size=0.2)\n",
        "test = create_test_dataset(images_test,labels_test[:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90240, 1, 28, 28) (90240,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqRy7BiQJ-3-",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "train_loader_t1 = DataLoader(train, batch_size=4,\n",
        "                        shuffle=True)\n",
        "val_loader_t1 = DataLoader(val, batch_size=4,\n",
        "                        shuffle=True)\n",
        "test_loader_t1 = DataLoader(test, batch_size=4,\n",
        "                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egptTAcFVVfm",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UqfbD4MZVVfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet_T1(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),         \n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),\n",
        "            nn.Conv2d(6, 16, 5),  \n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2)   \n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(256,120),        \n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120,84),       \n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84,2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4fT3ifZUVVf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_t1 = LeNet_T1().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt_t1 = optim.Adam(net_t1.parameters())\n",
        "\n",
        "MODEL_T1_PATH = PATH + '/trained_models/model_t1.pth'\n",
        "\n",
        "if load_and_save_mode:\n",
        "  checkpoint = torch.load(MODEL_T1_PATH)\n",
        "  net_t1.load_state_dict(checkpoint['model_state_dict'])\n",
        "  opt_t1.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  # epoch = checkpoint['epoch']\n",
        "  # loss = checkpoint['loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_gIVaGVEVVgN",
        "colab_type": "code",
        "outputId": "ed9edbdf-ee80-4a11-e531-63336fbcb799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "train_model(train_loader_t1,val_loader_t1,test_loader_t1,net_t1,loss_fn,opt_t1,max_epochs=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-ad4f61a0733f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_t1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader_t1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader_t1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_t1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_t1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-142-b41d83777abb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, net, loss_fn, opt, max_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-74871b77643e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#         print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#         print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErJ_zf_aFfVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new train and test functions\n",
        "# for epoch in range(1, 3 + 1):\n",
        "#                 train_v2(train_loader,net_t1,loss_fn,opt_t1,epoch)\n",
        "#                 test_v2(val_loader,net_t1,loss_fn,epoch,train_acc=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS5kGeiNpUEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_and_save_mode:\n",
        "  torch.save({\n",
        "              # 'epoch': epoch,\n",
        "              'model_state_dict': net_t1.state_dict(),\n",
        "              'optimizer_state_dict': opt_t1.state_dict(),\n",
        "              # 'loss': loss,\n",
        "              }, MODEL_T1_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMiIDCT8YLkz",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXGTFY28YShg",
        "colab": {}
      },
      "source": [
        "data_iter_t1 = iter(train_loader_t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "YfW6-6d_YShn",
        "colab": {}
      },
      "source": [
        "net_t1.cpu()\n",
        "for i in range(50):\n",
        "  batch_t1 = data_iter_t1.next()\n",
        "  show_images_batch(batch_t1)\n",
        "  out = net_t1(batch_t1[0])\n",
        "  _, pred = torch.max(out,1)\n",
        "  print(pred)\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "amsQS6c6K0mO"
      },
      "source": [
        "## Accuracy on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGpR0ThbK0me",
        "outputId": "0c3deab5-c5c0-412a-e71b-4821efa7066e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "net_t1.to(device)\n",
        "evaluation(test_loader_t1,net_t1,calc_loss=False,loss_fn=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.35106382978724"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUq1arxXVVgS",
        "colab_type": "text"
      },
      "source": [
        "# Task 2\n",
        "We are using different labels for train and evaluation purposes.\n",
        "\n",
        "Train Labels:\n",
        "if letter : 0-> vowel , 1-> consonant\n",
        "if digit : 0-> even, 1-> odd\n",
        "\n",
        "Test Labels:\n",
        "0-> digit, even\n",
        "1-> digit, odd\n",
        "2-> letter, vowel\n",
        "3-> letter, consonant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBD99MrvVVgV",
        "colab_type": "text"
      },
      "source": [
        "## DataSet And DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9YIbz9lK2QJ",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "digits_train_df = train_df.loc[train_df['labels_t1']==0]\n",
        "digits_test_df = test_df.loc[test_df['labels_t1']==0]\n",
        "\n",
        "letters_train_df = train_df.loc[train_df['labels_t1']==1]\n",
        "letters_test_df = test_df.loc[test_df['labels_t1']==1]\n",
        "\n",
        "digit_images_train = digits_train_df[images_columns].values\n",
        "letter_images_train = letters_train_df[images_columns].values\n",
        "digit_labels_train = digits_train_df['labels_t2'].values\n",
        "letter_labels_train = letters_train_df['labels_t2'].values\n",
        "\n",
        "digit_images_test = digits_test_df[images_columns].values\n",
        "letter_images_test = letters_test_df[images_columns].values\n",
        "digit_labels_test = digits_test_df['labels_t2'].values\n",
        "letter_labels_test = letters_test_df['labels_t2'].values\n",
        "\n",
        "## for evaluation only\n",
        "labels_train_t2_eval = train_df['labels_t2_eval'].values\n",
        "labels_test_t2_eval = test_df['labels_t2_eval'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "epLQoAB9VVi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training data and Labels\n",
        "digits_train_dataset, digits_val_dataset = create_train_val_dataset(digit_images_train,digit_labels_train)\n",
        "digits_test_dataset = create_test_dataset(digit_images_test,digit_labels_test)\n",
        "\n",
        "letters_train_dataset, letters_val_dataset = create_train_val_dataset(letter_images_train,letter_labels_train)\n",
        "letters_test_dataset = create_test_dataset(letter_images_test,letter_labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM6U0D2HUI1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_for_eval = create_test_dataset(images_test,labels_test_t2_eval)\n",
        "test_loader_eval = DataLoader(test_set_for_eval, batch_size=1,\n",
        "                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPB29MmkVVjJ",
        "colab_type": "text"
      },
      "source": [
        "## Model For Digits and Letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XqHhXpZNVVjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet_T2(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(256,120),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84,2)\n",
        "           \n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av5hMxoUVVjS",
        "colab_type": "text"
      },
      "source": [
        "## Training Digits Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxb51IJraATy",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YFAD87JeVVjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits_net= LeNet_T2().to(device)\n",
        "loss_fn_t2_digits = nn.CrossEntropyLoss()\n",
        "opt_t2_digits = optim.Adam(digits_net.parameters(),lr=0.01, betas=(0.9, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "KERROvtvTul1",
        "colab": {}
      },
      "source": [
        "\n",
        "MODEL_T2_DIGITS_PATH = PATH + '/trained_models/model_t2_digit.pth'\n",
        "\n",
        "if load_and_save_mode:\n",
        "  checkpoint = torch.load(MODEL_T2_DIGITS_PATH)\n",
        "  digits_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  opt_t2_digits.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qBgkM634VVjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader_t2_digits = DataLoader(digits_train_dataset, batch_size=4,\n",
        "                        shuffle=True)\n",
        "val_loader_t2_digits = DataLoader(digits_val_dataset, batch_size=4,\n",
        "                        shuffle=True)\n",
        "test_loader_t2_digits = DataLoader(digits_test_dataset, batch_size=4,\n",
        "                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bXdW9KWeVVjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(train_loader_t2_digits,val_loader_t2_digits,test_loader_t2_digits,digits_net,loss_fn_t2_digits,opt_t2_digits,max_epochs=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmGdFIoPsrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new train and test functions\n",
        "digits_net.to(device)\n",
        "loss_epoch_arr =[]\n",
        "for epoch in range(1, 2 + 1):\n",
        "    loss_epoch = train_v2(train_loader_t2_digits,digits_net,loss_fn_t2_digits,opt_t2_digits,epoch)\n",
        "    test_v2(val_loader_t2_digits,digits_net,loss_fn_t2_digits,epoch,train_acc=False)\n",
        "    loss_epoch_arr.append(loss_epoch)\n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urswbIXHUEKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_and_save_mode:\n",
        "  torch.save({\n",
        "              # 'epoch': epoch,\n",
        "              'model_state_dict': digits_net.state_dict(),\n",
        "              'optimizer_state_dict': opt_t2_digits.state_dict(),\n",
        "              # 'loss': loss,\n",
        "              }, MODEL_T2_DIGITS_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGpEZ2CITeW",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2olwCv3GZnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_iter_digits = iter(train_loader_t2_digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-y7d9alAVVjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(50):\n",
        "  batch_digits = data_iter_digits.next()\n",
        "  show_images_batch(batch_digits)\n",
        "  digits_net.cpu()\n",
        "  out = digits_net(batch_digits[0])\n",
        "  _, pred = torch.max(out,1)\n",
        "  print(pred)\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5yPCxarVVjj",
        "colab_type": "text"
      },
      "source": [
        "## Training Letters Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq7nOXpKaIG8",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lp7XP3-WVVjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "letters_net= LeNet_T2().to(device)\n",
        "loss_fn_t2_letters = nn.CrossEntropyLoss()\n",
        "opt_t2_letters = optim.Adam(letters_net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEpwdzN2VlJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_T2_LETTERS_PATH = PATH + '/trained_models/model_t2_letter.pth'\n",
        "\n",
        "if load_and_save_mode:\n",
        "  checkpoint = torch.load(MODEL_T2_LETTERS_PATH)\n",
        "  letters_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  opt_t2_letters.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SzjHP2UzVVjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader_t2_letters = DataLoader(letters_train_dataset, batch_size=4,\n",
        "                        shuffle=True)\n",
        "val_loader_t2_letters = DataLoader(letters_val_dataset, batch_size=4,\n",
        "                        shuffle=True)\n",
        "test_loader_t2_letters = DataLoader(letters_test_dataset, batch_size=4,\n",
        "                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CHd3tPatVVj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_model(train_loader_t2_letters,val_loader_t2_letters,test_loader_t2_letters,letters_net,loss_fn_t2_letters,opt_t2_letters,max_epochs=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG_JI0AnSeNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 2 + 1):\n",
        "    train_v2(train_loader_t2_letters,letters_net,loss_fn_t2_letters,opt_t2_letters,epoch)\n",
        "    test_v2(val_loader_t2_letters,letters_net,loss_fn_t2_letters,epoch,train_acc=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOcNREP_V03_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_and_save_mode:\n",
        "  torch.save({\n",
        "              # 'epoch': epoch,\n",
        "              'model_state_dict': letters_net.state_dict(),\n",
        "              'optimizer_state_dict': opt_t2_letters.state_dict(),\n",
        "              # 'loss': loss,\n",
        "              }, MODEL_T2_LETTERS_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GczxF8dDGtXH",
        "colab_type": "text"
      },
      "source": [
        "## Inference On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DLIAaaOCGy_q",
        "colab": {}
      },
      "source": [
        "data_iter_letters = iter(test_loader_t2_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "xI2BwV5nGy_1",
        "colab": {}
      },
      "source": [
        "for i in range(4):\n",
        "  batch_letters = data_iter_letters.next()\n",
        "  show_images_batch(batch_letters)\n",
        "  letters_net.cpu()\n",
        "  out = letters_net(batch_letters[0])\n",
        "  # print(out.shape)\n",
        "  _, pred = torch.max(out,1)\n",
        "  print(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrxNQ2ZoIOnN",
        "colab_type": "text"
      },
      "source": [
        "## Running digit/ letter model according to output of model of Task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9XTyt9pINl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#net_t1 -> letters_net/ digits_net\n",
        "# it is not able to perform for batch right now\n",
        "def vowel_consonant_even_odd_classifier(image):\n",
        "  # run digits/ letter classifier\n",
        "  output_1 = net_t1(image)\n",
        "  _, pred_1 = torch.max(output_1,1)\n",
        "  if pred_1==0:\n",
        "    # run even/odd classifier\n",
        "    output_2 = digits_net(image)\n",
        "    _, pred_2 = torch.max(output_2,1)\n",
        "    return 0 if pred_2==0 else 1\n",
        "  else:\n",
        "    # run vowel/ consonant classifier\n",
        "    output_2 = letters_net(image)\n",
        "    _, pred_2 = torch.max(output_2,1)\n",
        "    return 2 if pred_2==0 else 3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRldjdBxZiUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_iter_t1 = iter(test_loader_eval) # full data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99p24HZQWZjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits_net.cpu()\n",
        "letters_net.cpu()\n",
        "net_t1.cpu()\n",
        "\n",
        "for i in range(40):\n",
        "  batch = data_iter_t1.next()\n",
        "  show_images_batch(batch)\n",
        "  vowel_consonant_even_odd_classifier(batch[0])\n",
        "# net_t1(batch_letters[0][0].reshape(1,1,28,28)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "McQc5I5AKZt-"
      },
      "source": [
        "## Accuracy on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBdZQPAZW2s5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_task2(data_loader,classifier):\n",
        "  correct,total = 0, 0\n",
        "  for image, label in data_loader:\n",
        "    output = classifier(image)\n",
        "    if output ==label:\n",
        "      correct = correct+1\n",
        "    total += label.size(0)\n",
        "  return 100 * correct / total\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-lSLL2DcKZuL",
        "outputId": "f27d9204-c612-4a79-c102-f65178b1ff88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "net_t1.cpu()\n",
        "digits_net.cpu()\n",
        "letters_net.cpu()\n",
        "evaluate_task2(test_loader_eval,vowel_consonant_even_odd_classifier)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.65425531914893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EWqTdnznzUg",
        "colab_type": "text"
      },
      "source": [
        "# TASK 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfYAZyY9MHVc",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmLKYY96ukzS",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "train , val = create_train_val_dataset(images_train,labels_train[:,2],test_size=0.2)\n",
        "test = create_test_dataset(images_test,labels_test[:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7WadCNvNvSi",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLDc7p8VMMQ8",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mejtkHK_n1u8",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Copied LeNet Model From My Kaggle Notebook\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),         # (N, 1, 28, 28) -> (N,  6, 24, 24)\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),  # (N, 6, 24, 24) -> (N,  6, 12, 12)\n",
        "            nn.Conv2d(6, 16, 5),        # (N, 6, 12, 12) -> (N, 16, 8, 8)  \n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2)   # (N,16, 4, 4) -> (N, 16, 4, 4)\n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(256,120),         # (N, 400) -> (N, 120)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120,84),          # (N, 120) -> (N, 84)\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84,47)            # (N, 84)  -> (N, 10)\n",
        "            # note that we are not using softmax because it is not essential, just find the max value amongst all \n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p_BZHaHqcKx",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZa06JCAvrvX",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "net = LeNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o2Gb2lBHRR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_T3_PATH = PATH + '/trained_models/model_t3.pth'\n",
        "if load_and_save_mode:\n",
        "  checkpoint = torch.load(MODEL_T3_PATH)\n",
        "  net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  opt.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "trusted": true,
        "id": "y9k48Oi6M-V3",
        "colab": {}
      },
      "source": [
        "# train_model(train_loader,val_loader,test_loader,net,loss_fn,opt,max_epochs=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR92dlGIGrIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 3 + 1):\n",
        "                train_v2(train_loader,net,loss_fn,opt,epoch)\n",
        "                test_v2(val_loader,net,loss_fn,epoch,train_acc=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv2bj_YDHieo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_and_save_mode:\n",
        "  torch.save({\n",
        "              # 'epoch': epoch,\n",
        "              'model_state_dict': net.state_dict(),\n",
        "              'optimizer_state_dict': opt.state_dict(),\n",
        "              # 'loss': loss,\n",
        "              }, MODEL_T3_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_2Wsmd8OvwO",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rj7ojNQxOz2i",
        "colab": {}
      },
      "source": [
        "data_iter = iter(train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "KtBFoIgyOz2w",
        "colab": {}
      },
      "source": [
        "net.cpu()\n",
        "for i in range(100):\n",
        "  batch = data_iter.next()\n",
        "  show_images_batch(batch)\n",
        "  out = net(batch[0])\n",
        "  # print(out.shape)\n",
        "  _, pred = torch.max(out,1)\n",
        "  print('Predictions : ' ,[chr(index_to_ascii[i]) for i in pred.numpy()])\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BWWAtCChATqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(train_loader,net,47,classes=classes_t3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDTS5VOUSJWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.savefig('confusion.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfUudbKTKAX0",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UburBbiJKDdz",
        "colab_type": "code",
        "outputId": "bd7a00e4-42e1-429f-997f-126f23929407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "evaluation(test_loader,net,calc_loss=False,loss_fn=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.63297872340425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXGA7oVOTrGn",
        "colab_type": "text"
      },
      "source": [
        "#Saving Models to Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMPFPGPbTvBn",
        "colab_type": "code",
        "outputId": "4de19056-b6f8-4c94-dba0-e97f398d201b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "torch.save(net_t1,'task1_model.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LeNet_T1. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62RRe8kvZhwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('task1_model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHB_Dy7tZ3tQ",
        "colab_type": "code",
        "outputId": "591bac32-0e99-4b1e-b47e-bff4318bbd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "torch.save(digits_net,'task2_digits_model.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LeNet_T2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdNKx_Tmaqfp",
        "colab_type": "code",
        "outputId": "2548efd2-a437-482a-be19-38ac18cfac14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "torch.save(letters_net,'task2_letters_model.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LeNet_T2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT5An7ppa2c1",
        "colab_type": "code",
        "outputId": "896f6823-3996-4386-82dd-63919857f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "torch.save(net,'task3_model.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LeNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdNX3rSzibk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i, j in zip (range(47),classes_t3):\n",
        "#   print(str(i) +' -> '+j +' <br/>')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}